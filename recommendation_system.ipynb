{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation system",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TypicalDefender/recommendation-system/blob/master/recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfLHsm8ZNe_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VSLx6gUweUi",
        "colab_type": "text"
      },
      "source": [
        "Capstone Project For Recommendation System. By Shivangi Nagaich"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT3jQkx4Dik9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kcv6yzsNmg3",
        "colab_type": "code",
        "outputId": "63dc43d5-2afa-4d19-e878-4cae9ab50d5b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce34561e-4548-4284-971c-c52e5dface7c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ce34561e-4548-4284-971c-c52e5dface7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving shared_articles.csv to shared_articles.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNBjtyOMOGVU",
        "colab_type": "code",
        "outputId": "1915aacb-5cb6-4cce-823a-f0294cd886d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "import io\n",
        "articles_df = pd.read_csv(io.StringIO(uploaded['shared_articles.csv'].decode('utf-8')))\n",
        "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
        "articles_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  ... lang\n",
              "1  1459193988  ...   en\n",
              "2  1459194146  ...   en\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLbflLfHwszs",
        "colab_type": "text"
      },
      "source": [
        "Contains information about the articles shared in the platform. Each article has its sharing date (timestamp), the original url, title, content in plain text, the article' lang (Portuguese: pt or English: en) and information about the user who shared the article (author).\n",
        "\n",
        "There are two possible event types at a given timestamp:\n",
        "\n",
        "CONTENT SHARED: The article was shared in the platform and is available for users.\n",
        "CONTENT REMOVED: The article was removed from the platform and not available for further recommendation.\n",
        "For the sake of simplicity, we only consider here the \"CONTENT SHARED\" event type, assuming (naively) that all articles were available during the whole one year period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnrG3rfmPmeV",
        "colab_type": "code",
        "outputId": "9d548be9-a84e-4d92-e077-38cbb7747db3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b8c8032-0f09-4b03-a3ea-9bb3714388be\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0b8c8032-0f09-4b03-a3ea-9bb3714388be\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving users_interactions.csv to users_interactions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIaBkOWdP6p2",
        "colab_type": "code",
        "outputId": "3050b586-75e0-4686-acd0-f2db4da0180c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "interactions_df = pd.read_csv(io.StringIO(uploaded['users_interactions.csv'].decode('utf-8')))\n",
        "interactions_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userRegion  userCountry\n",
              "0  1465413032      VIEW  ...         NaN          NaN\n",
              "1  1465412560      VIEW  ...          NY           US\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FqDr4llxCTZ",
        "colab_type": "text"
      },
      "source": [
        "Contains logs of user interactions on shared articles. It can be joined to articles_shared.csv by contentId column.\n",
        "\n",
        "The eventType values are:\n",
        "\n",
        "VIEW: The user has opened the article.\n",
        "LIKE: The user has liked the article.\n",
        "COMMENT CREATED: The user created a comment in the article.\n",
        "FOLLOW: The user chose to be notified on any new comment in the article.\n",
        "BOOKMARK: The user has bookmarked the article for easy return in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27L34eNnQ3mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data munging\n",
        "event_type_strength = {\n",
        "   'VIEW': 1.0,\n",
        "   'LIKE': 2.0, \n",
        "   'BOOKMARK': 2.5, \n",
        "   'FOLLOW': 3.0,\n",
        "   'COMMENT CREATED': 4.0,  \n",
        "}\n",
        "\n",
        "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibmeAlavxHfr",
        "colab_type": "text"
      },
      "source": [
        "As there are different interactions types, we associate them with a weight or strength, assuming that, for example, a comment in an article indicates a higher interest of the user on the item than a like, or than a simple view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbDol84rRFtd",
        "colab_type": "code",
        "outputId": "6bbcb0f3-8e72-423f-d7c3-f97f69c735a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
        "print('# users: %d' % len(users_interactions_count_df))\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
        "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# users: 1895\n",
            "# users with at least 5 interactions: 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWWWgKtZxMEQ",
        "colab_type": "text"
      },
      "source": [
        "Recommender systems have a problem known as user cold-start, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences.\n",
        "For this reason, we are keeping in the dataset only users with at leas 5 interactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-h-tX4FRNtj",
        "colab_type": "code",
        "outputId": "688a7c81-257e-4432-c99e-836c30f87cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('# of interactions: %d' % len(interactions_df))\n",
        "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
        "               how = 'right',\n",
        "               left_on = 'personId',\n",
        "               right_on = 'personId')\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of interactions: 72312\n",
            "# of interactions from users with at least 5 interactions: 69868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzxM8DkGRSkW",
        "colab_type": "code",
        "outputId": "daca961b-baf0-47b2-aaef-4dc8f5d46151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "    \n",
        "interactions_full_df = interactions_from_selected_users_df \\\n",
        "                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n",
        "                    .apply(smooth_user_preference).reset_index()\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
        "interactions_full_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of unique user/item interactions: 39106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8949113594875411859</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8187220755213888616</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-7423191370472335463</td>\n",
              "      <td>3.169925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-7331393944609614247</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6872546942144599345</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6728844082024523434</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6590819806697898649</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6558712014192834002</td>\n",
              "      <td>1.584963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              personId            contentId  eventStrength\n",
              "0 -9223121837663643404 -8949113594875411859       1.000000\n",
              "1 -9223121837663643404 -8377626164558006982       1.000000\n",
              "2 -9223121837663643404 -8208801367848627943       1.000000\n",
              "3 -9223121837663643404 -8187220755213888616       1.000000\n",
              "4 -9223121837663643404 -7423191370472335463       3.169925\n",
              "5 -9223121837663643404 -7331393944609614247       1.000000\n",
              "6 -9223121837663643404 -6872546942144599345       1.000000\n",
              "7 -9223121837663643404 -6728844082024523434       1.000000\n",
              "8 -9223121837663643404 -6590819806697898649       1.000000\n",
              "9 -9223121837663643404 -6558712014192834002       1.584963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPW1g6JpxSUm",
        "colab_type": "text"
      },
      "source": [
        " users are allowed to view an article many times, and interact with them in different ways (eg. like or comment). Thus, to model the user interest on a given article, we aggregate all the interactions the user has performed in an item by a weighted sum of interaction type strength and apply a log transformation to smooth the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VnxFgKPRY0z",
        "colab_type": "code",
        "outputId": "3a627c40-970e-4d36-d8c7-70b002ab64b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
        "                                   stratify=interactions_full_df['personId'], \n",
        "                                   test_size=0.20,\n",
        "                                   random_state=42)\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 31284\n",
            "# interactions on Test set: 7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZFQucR2xopi",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**\n",
        "We are using here a simple cross-validation approach named holdout, in which a random data sample (20% in this case) are kept aside in the training process, and exclusively used for evaluation. All evaluation metrics reported here are computed using the test set.\n",
        "\n",
        "Ps. A more robust evaluation approach could be to split train and test sets by a reference date, where the train set is composed by all interactions before that date, and the test set are interactions after that date. For the sake of simplicity, we chose the first random approach for this notebook, but you may want to try the second approach to better simulate how the recsys would perform in production predicting \"future\" users interactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN0BYbRKRftb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('personId')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0142GUvkBpYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_items_interacted(person_id, interactions_df):\n",
        "    # Get the user's data and merge in the movie information.\n",
        "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f2saqeHFc7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "\n",
        "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
        "        all_items = set(articles_df['contentId'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "        #Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
        "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
        "\n",
        "        #Getting a ranked recommendation list from a model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, \n",
        "                                               items_to_ignore=get_items_interacted(person_id, \n",
        "                                                                                    interactions_train_indexed_df), \n",
        "                                               topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "        #For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "            #Getting a random sample (100) items the user has not interacted \n",
        "            #(to represent items that are assumed to be no relevant to the user)\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
        "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
        "                                                                          seed=item_id%(2**32))\n",
        "\n",
        "            #Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
        "            valid_recs = valid_recs_df['contentId'].values\n",
        "            #Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
        "        #when mixed with a set of non-relevant items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
        "                          'hits@10_count':hits_at_10_count, \n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return person_metrics\n",
        "\n",
        "    def evaluate_model(self, model):\n",
        "        #print('Running evaluation for users')\n",
        "        people_metrics = []\n",
        "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            #if idx % 100 == 0 and idx > 0:\n",
        "            #    print('%d users processed' % idx)\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
        "            person_metrics['_person_id'] = person_id\n",
        "            people_metrics.append(person_metrics)\n",
        "        print('%d users processed' % idx)\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
        "                            .sort_values('interacted_count', ascending=False)\n",
        "        \n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        \n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}    \n",
        "        return global_metrics, detailed_results_df\n",
        "    \n",
        "model_evaluator = ModelEvaluator()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuucVJ1SyBBt",
        "colab_type": "text"
      },
      "source": [
        "In Recommender Systems, there are a set metrics commonly used for evaluation. We chose to work with Top-N accuracy metrics, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\n",
        "This evaluation method works as follows:\n",
        "\n",
        "For each user\n",
        "For each item the user has interacted in test set\n",
        "Sample 100 other items the user has never interacted.\n",
        "Ps. Here we naively assume those non interacted items are not relevant to the user, which might not be true, as the user may simply not be aware of those not interacted items. But let's keep this assumption.\n",
        "Ask the recommender model to produce a ranked list of recommended items, from a set composed one interacted item and the 100 non-interacted (\"non-relevant!) items\n",
        "Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
        "Aggregate the global Top-N accuracy metrics\n",
        "The Top-N accuracy metric choosen was Recall@N which evaluates whether the interacted item is among the top N items (hit) in the ranked list of 101 recommendations for a user.\n",
        "Ps. Other popular ranking metrics are NDCG@N and MAP@N, whose score calculation takes into account the position of the relevant item in the ranked list (max. value if relevant item is in the first position)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NamFUtSYFkQG",
        "colab_type": "code",
        "outputId": "ebaf5e28-5b82-46ff-f9ee-5c6172acc8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "#popularity model\n",
        "#Computes the most popular items\n",
        "item_popularity_df = interactions_full_df.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
        "item_popularity_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4029704725707465084</td>\n",
              "      <td>307.733799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6783772548752091658</td>\n",
              "      <td>233.762157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-133139342397538859</td>\n",
              "      <td>228.024567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>197.107608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6843047699859121724</td>\n",
              "      <td>193.825208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8224860111193157980</td>\n",
              "      <td>189.044680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2358756719610361882</td>\n",
              "      <td>183.110951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2581138407738454418</td>\n",
              "      <td>180.282876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7507067965574797372</td>\n",
              "      <td>179.094002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1469580151036142903</td>\n",
              "      <td>170.548969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             contentId  eventStrength\n",
              "0 -4029704725707465084     307.733799\n",
              "1 -6783772548752091658     233.762157\n",
              "2  -133139342397538859     228.024567\n",
              "3 -8208801367848627943     197.107608\n",
              "4 -6843047699859121724     193.825208\n",
              "5  8224860111193157980     189.044680\n",
              "6 -2358756719610361882     183.110951\n",
              "7  2581138407738454418     180.282876\n",
              "8  7507067965574797372     179.094002\n",
              "9  1469580151036142903     170.548969"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCZnOLAcFsJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PopularityRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Popularity'\n",
        "    \n",
        "    def __init__(self, popularity_df, items_df=None):\n",
        "        self.popularity_df = popularity_df\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Recommend the more popular items that the user hasn't seen yet.\n",
        "        recommendations_df = self.popularity_df[~self.popularity_df['contentId'].isin(items_to_ignore)] \\\n",
        "                               .sort_values('eventStrength', ascending = False) \\\n",
        "                               .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "popularity_model = PopularityRecommender(item_popularity_df, articles_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlIH9-fDFzKA",
        "colab_type": "code",
        "outputId": "e29e9c40-d529-48bf-a171-80e7a1f7a352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "print('Evaluating Popularity recommendation model...')\n",
        "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\n",
        "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
        "pop_detailed_results_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Popularity recommendation model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Popularity', 'recall@5': 0.2417540271030427, 'recall@10': 0.37292252620813093}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_person_id</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>recall@5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "      <td>192</td>\n",
              "      <td>0.260417</td>\n",
              "      <td>0.145833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-2626634673110551643</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>134</td>\n",
              "      <td>0.186567</td>\n",
              "      <td>0.089552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>130</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1443636648652872475</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.042735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>-2979881261169775358</td>\n",
              "      <td>40</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.284091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>-3596626804281480007</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>80</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1116121227607581999</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>73</td>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.273973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>692689608292948411</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>69</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.246377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-9016528795238256703</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "      <td>69</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.202899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3636910968448833585</td>\n",
              "      <td>28</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.308824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              _person_id  hits@10_count  ...  recall@10  recall@5\n",
              "76   3609194402293569455             50  ...   0.260417  0.145833\n",
              "17  -2626634673110551643             25  ...   0.186567  0.089552\n",
              "16  -1032019229384696495             23  ...   0.176923  0.100000\n",
              "10  -1443636648652872475              9  ...   0.076923  0.042735\n",
              "82  -2979881261169775358             40  ...   0.454545  0.284091\n",
              "161 -3596626804281480007             18  ...   0.225000  0.150000\n",
              "65   1116121227607581999             33  ...   0.452055  0.273973\n",
              "81    692689608292948411             23  ...   0.333333  0.246377\n",
              "106 -9016528795238256703             18  ...   0.260870  0.202899\n",
              "52   3636910968448833585             28  ...   0.411765  0.308824\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbnVYCCVF2bz",
        "colab_type": "code",
        "outputId": "114d845f-b87b-4660-f970-e03dd54f402b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "#content based filtering\n",
        "stopwords_list = stopwords.words('english') + stopwords.words('portuguese')\n",
        "\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                     ngram_range=(1, 2),\n",
        "                     min_df=0.003,\n",
        "                     max_df=0.5,\n",
        "                     max_features=5000,\n",
        "                     stop_words=stopwords_list)\n",
        "\n",
        "item_ids = articles_df['contentId'].tolist()\n",
        "tfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \"\" + articles_df['text'])\n",
        "tfidf_feature_names = vectorizer.get_feature_names()\n",
        "tfidf_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3047x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 638928 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mHozDYGHlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_item_profile(item_id):\n",
        "    idx = item_ids.index(item_id)\n",
        "    item_profile = tfidf_matrix[idx:idx+1]\n",
        "    return item_profile\n",
        "\n",
        "def get_item_profiles(ids):\n",
        "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
        "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
        "    return item_profiles\n",
        "\n",
        "def build_users_profile(person_id, interactions_indexed_df):\n",
        "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
        "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
        "    \n",
        "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n",
        "    #Weighted average of item profiles by the interactions strength\n",
        "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
        "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
        "    return user_profile_norm\n",
        "\n",
        "def build_users_profiles(): \n",
        "    interactions_indexed_df = interactions_full_df[interactions_full_df['contentId'] \\\n",
        "                                                   .isin(articles_df['contentId'])].set_index('personId')\n",
        "    user_profiles = {}\n",
        "    for person_id in interactions_indexed_df.index.unique():\n",
        "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
        "    return user_profiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOAjc4Y0y-Z3",
        "colab_type": "code",
        "outputId": "1439cc6a-cf9f-47f0-de35-dd68422940bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "user_profiles = build_users_profiles()\n",
        "len(user_profiles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaWKq9MRzBkk",
        "colab_type": "code",
        "outputId": "4a91f663-bef6-4d34-e748-024a9e2dbfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "myprofile = user_profiles[-1479311724257856983]\n",
        "print(myprofile.shape)\n",
        "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
        "                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
        "             columns=['token', 'relevance'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.305655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>machine learning</td>\n",
              "      <td>0.255557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine</td>\n",
              "      <td>0.246095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google</td>\n",
              "      <td>0.208590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data</td>\n",
              "      <td>0.172509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ai</td>\n",
              "      <td>0.136818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>algorithms</td>\n",
              "      <td>0.102396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>graph</td>\n",
              "      <td>0.098438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>like</td>\n",
              "      <td>0.096970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>language</td>\n",
              "      <td>0.083993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>people</td>\n",
              "      <td>0.077122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>use</td>\n",
              "      <td>0.073203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>models</td>\n",
              "      <td>0.073168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>deep</td>\n",
              "      <td>0.072377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>deep learning</td>\n",
              "      <td>0.071892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>research</td>\n",
              "      <td>0.071503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>company</td>\n",
              "      <td>0.071293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>intelligence</td>\n",
              "      <td>0.070650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>human</td>\n",
              "      <td>0.070126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>artificial</td>\n",
              "      <td>0.068062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               token  relevance\n",
              "0           learning   0.305655\n",
              "1   machine learning   0.255557\n",
              "2            machine   0.246095\n",
              "3             google   0.208590\n",
              "4               data   0.172509\n",
              "5                 ai   0.136818\n",
              "6         algorithms   0.102396\n",
              "7              graph   0.098438\n",
              "8               like   0.096970\n",
              "9           language   0.083993\n",
              "10            people   0.077122\n",
              "11               use   0.073203\n",
              "12            models   0.073168\n",
              "13              deep   0.072377\n",
              "14     deep learning   0.071892\n",
              "15          research   0.071503\n",
              "16           company   0.071293\n",
              "17      intelligence   0.070650\n",
              "18             human   0.070126\n",
              "19        artificial   0.068062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-qHXYNPzHlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContentBasedRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Content-Based'\n",
        "    \n",
        "    def __init__(self, items_df=None):\n",
        "        self.item_ids = item_ids\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
        "        #Computes the cosine similarity between the user profile and all item profiles\n",
        "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
        "        #Gets the top similar items\n",
        "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
        "        #Sort the similar items by similarity\n",
        "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
        "        return similar_items\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
        "        #Ignores items the user has already interacted\n",
        "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
        "        \n",
        "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n",
        "                                    .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "content_based_recommender_model = ContentBasedRecommender(articles_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k5ltvQzzOcE",
        "colab_type": "code",
        "outputId": "d6442526-8a66-4009-d4fa-9587dd2b13d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "print('Evaluating Content-Based Filtering model...')\n",
        "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
        "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
        "cb_detailed_results_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Content-Based Filtering model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Content-Based', 'recall@5': 0.41459984658655075, 'recall@10': 0.5241626182562005}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_person_id</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>recall@5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>192</td>\n",
              "      <td>0.135417</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-2626634673110551643</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>134</td>\n",
              "      <td>0.261194</td>\n",
              "      <td>0.156716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>34</td>\n",
              "      <td>22</td>\n",
              "      <td>130</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.169231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1443636648652872475</td>\n",
              "      <td>54</td>\n",
              "      <td>34</td>\n",
              "      <td>117</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.290598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>-2979881261169775358</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>88</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>-3596626804281480007</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>80</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1116121227607581999</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>73</td>\n",
              "      <td>0.205479</td>\n",
              "      <td>0.136986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>692689608292948411</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.159420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-9016528795238256703</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>69</td>\n",
              "      <td>0.144928</td>\n",
              "      <td>0.072464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3636910968448833585</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>68</td>\n",
              "      <td>0.161765</td>\n",
              "      <td>0.058824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              _person_id  hits@10_count  ...  recall@10  recall@5\n",
              "76   3609194402293569455             26  ...   0.135417  0.083333\n",
              "17  -2626634673110551643             35  ...   0.261194  0.156716\n",
              "16  -1032019229384696495             34  ...   0.261538  0.169231\n",
              "10  -1443636648652872475             54  ...   0.461538  0.290598\n",
              "82  -2979881261169775358             15  ...   0.170455  0.090909\n",
              "161 -3596626804281480007             23  ...   0.287500  0.175000\n",
              "65   1116121227607581999             15  ...   0.205479  0.136986\n",
              "81    692689608292948411             20  ...   0.289855  0.159420\n",
              "106 -9016528795238256703             10  ...   0.144928  0.072464\n",
              "52   3636910968448833585             11  ...   0.161765  0.058824\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLR39t_zRVc",
        "colab_type": "code",
        "outputId": "d9db7fd4-901a-46f9-ac77-5e4dcea6bdaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\n",
        "users_items_pivot_matrix_df = interactions_train_df.pivot(index='personId', \n",
        "                                                          columns='contentId', \n",
        "                                                          values='eventStrength').fillna(0)\n",
        "\n",
        "users_items_pivot_matrix_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>contentId</th>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <th>-9161596996229760398</th>\n",
              "      <th>-9160910454530522563</th>\n",
              "      <th>-9157338616628196758</th>\n",
              "      <th>-9153494109165200346</th>\n",
              "      <th>-9147114693160126293</th>\n",
              "      <th>-9137036168156595470</th>\n",
              "      <th>-9128741757954228992</th>\n",
              "      <th>-9128652074338368262</th>\n",
              "      <th>-9107331682787867601</th>\n",
              "      <th>-9105040345021932755</th>\n",
              "      <th>-9103776596534246502</th>\n",
              "      <th>-9102431381393428051</th>\n",
              "      <th>-9100490342054218852</th>\n",
              "      <th>-9099155556042679205</th>\n",
              "      <th>-9095002324981651252</th>\n",
              "      <th>-9092333155845304874</th>\n",
              "      <th>-9090514312860140897</th>\n",
              "      <th>-9089854794058353436</th>\n",
              "      <th>-9086955082453789880</th>\n",
              "      <th>-9083294960368598209</th>\n",
              "      <th>-9081753261356157170</th>\n",
              "      <th>-9080873096647717414</th>\n",
              "      <th>-9076501258717815738</th>\n",
              "      <th>-9073210245497295284</th>\n",
              "      <th>-9071883412530082330</th>\n",
              "      <th>-9064100704535292718</th>\n",
              "      <th>-9056114023474725450</th>\n",
              "      <th>-9055044275358686874</th>\n",
              "      <th>-9050450867630628092</th>\n",
              "      <th>-9045753673721269477</th>\n",
              "      <th>...</th>\n",
              "      <th>8962537427807366481</th>\n",
              "      <th>8963770574956550187</th>\n",
              "      <th>8963938873430212934</th>\n",
              "      <th>8968837261991914049</th>\n",
              "      <th>8969476626572775042</th>\n",
              "      <th>8974280745225397183</th>\n",
              "      <th>8982094176562780806</th>\n",
              "      <th>8993230615635349817</th>\n",
              "      <th>9004099881383415529</th>\n",
              "      <th>9026402401132606773</th>\n",
              "      <th>9028580484484026894</th>\n",
              "      <th>9032993320407723266</th>\n",
              "      <th>9033884391004475493</th>\n",
              "      <th>9038543365726770177</th>\n",
              "      <th>9042192299854648021</th>\n",
              "      <th>9045808098977760576</th>\n",
              "      <th>9054050762437897017</th>\n",
              "      <th>9056727675613132316</th>\n",
              "      <th>9060231864899459154</th>\n",
              "      <th>9079880752026843473</th>\n",
              "      <th>9091641298512813712</th>\n",
              "      <th>9112765177685685246</th>\n",
              "      <th>9121100366909552616</th>\n",
              "      <th>9122627895188486603</th>\n",
              "      <th>9124439338148818380</th>\n",
              "      <th>9128267824356972069</th>\n",
              "      <th>9136323715291453594</th>\n",
              "      <th>9151634133568930081</th>\n",
              "      <th>9168028029170358424</th>\n",
              "      <th>9175693555063886126</th>\n",
              "      <th>9191014301634017491</th>\n",
              "      <th>9207286802575546269</th>\n",
              "      <th>9208127165664287660</th>\n",
              "      <th>9209629151177723638</th>\n",
              "      <th>9209886322932807692</th>\n",
              "      <th>9213260650272029784</th>\n",
              "      <th>9215261273565326920</th>\n",
              "      <th>9217155070834564627</th>\n",
              "      <th>9220445660318725468</th>\n",
              "      <th>9222265156747237864</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9188188261933657343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9172914609055320039</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9156344805277471150</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9120685872592674274</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9109785559521267180</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 2926 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "contentId             -9222795471790223670  ...   9222265156747237864\n",
              "personId                                    ...                      \n",
              "-9223121837663643404                   0.0  ...                   0.0\n",
              "-9212075797126931087                   0.0  ...                   0.0\n",
              "-9207251133131336884                   0.0  ...                   0.0\n",
              "-9199575329909162940                   0.0  ...                   0.0\n",
              "-9196668942822132778                   0.0  ...                   0.0\n",
              "-9188188261933657343                   0.0  ...                   0.0\n",
              "-9172914609055320039                   0.0  ...                   0.0\n",
              "-9156344805277471150                   0.0  ...                   0.0\n",
              "-9120685872592674274                   0.0  ...                   0.0\n",
              "-9109785559521267180                   0.0  ...                   0.0\n",
              "\n",
              "[10 rows x 2926 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7sDz8QMzWrX",
        "colab_type": "code",
        "outputId": "8b5e670f-30e1-4352-b896-31d66f5b826d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "users_items_pivot_matrix = users_items_pivot_matrix_df.as_matrix()\n",
        "users_items_pivot_matrix[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 2., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7d8sW3LzZnM",
        "colab_type": "code",
        "outputId": "684374ff-e9f5-4c35-c29e-d2872e9b8480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "users_ids = list(users_items_pivot_matrix_df.index)\n",
        "users_ids[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-9223121837663643404,\n",
              " -9212075797126931087,\n",
              " -9207251133131336884,\n",
              " -9199575329909162940,\n",
              " -9196668942822132778,\n",
              " -9188188261933657343,\n",
              " -9172914609055320039,\n",
              " -9156344805277471150,\n",
              " -9120685872592674274,\n",
              " -9109785559521267180]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIM5T_8Dzcjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsafPS23zfX6",
        "colab_type": "code",
        "outputId": "1a19fedd-c73d-41c9-d3fb-b7e6d29a1190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "U.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1140, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFRG47KUzicX",
        "colab_type": "code",
        "outputId": "2f482a31-d7eb-46e3-a458-bae3f25445fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Vt.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 2926)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o71ep3FEzlRY",
        "colab_type": "code",
        "outputId": "fedb733f-b1dc-41f3-b4c2-08342df7cafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtYVMV31zo_c",
        "colab_type": "code",
        "outputId": "c5a81d22-5b0d-46a1-d36b-5b3935bba896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
        "all_user_predicted_ratings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01039915,  0.00081872, -0.01725263, ...,  0.00140708,\n",
              "         0.0110647 ,  0.00226063],\n",
              "       [-0.00019285, -0.00031318, -0.00264624, ...,  0.00251658,\n",
              "         0.00017609, -0.00189488],\n",
              "       [-0.01254721,  0.0065947 , -0.00590676, ...,  0.00698975,\n",
              "        -0.01015696,  0.01154572],\n",
              "       ...,\n",
              "       [-0.02995379,  0.00805715, -0.01846307, ..., -0.01083078,\n",
              "        -0.00118591,  0.0096798 ],\n",
              "       [-0.01845505,  0.00467019,  0.01219602, ...,  0.00409507,\n",
              "         0.00019482, -0.00752562],\n",
              "       [-0.01506374,  0.00327732,  0.13391269, ..., -0.01191815,\n",
              "         0.06422074,  0.01303244]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzxr98MezsAM",
        "colab_type": "code",
        "outputId": "8f6ef55c-1084-4f99-acc0-366515492789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
        "cf_preds_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <th>-9188188261933657343</th>\n",
              "      <th>-9172914609055320039</th>\n",
              "      <th>-9156344805277471150</th>\n",
              "      <th>-9120685872592674274</th>\n",
              "      <th>-9109785559521267180</th>\n",
              "      <th>-9063420486253202900</th>\n",
              "      <th>-9060214117327732109</th>\n",
              "      <th>-9047547311469006438</th>\n",
              "      <th>-9016528795238256703</th>\n",
              "      <th>-9009798162809551896</th>\n",
              "      <th>-9001583565812478106</th>\n",
              "      <th>-8994220765455693336</th>\n",
              "      <th>-8909668725653743114</th>\n",
              "      <th>-8891033171626175843</th>\n",
              "      <th>-8860671864164757449</th>\n",
              "      <th>-8854674432071487111</th>\n",
              "      <th>-8853658195208337106</th>\n",
              "      <th>-8845298781299428018</th>\n",
              "      <th>-8830250090736356260</th>\n",
              "      <th>-8823950498314351783</th>\n",
              "      <th>-8802075878443651241</th>\n",
              "      <th>-8784674845716296727</th>\n",
              "      <th>-8781635134606732409</th>\n",
              "      <th>-8781306637602263252</th>\n",
              "      <th>-8763398617720485024</th>\n",
              "      <th>-8738496712327699923</th>\n",
              "      <th>-8719462623048086192</th>\n",
              "      <th>-8704807962619440953</th>\n",
              "      <th>-8699750646678621887</th>\n",
              "      <th>-8694104221113176052</th>\n",
              "      <th>-8686631410634491662</th>\n",
              "      <th>-8674958742744576254</th>\n",
              "      <th>-8672331451814079632</th>\n",
              "      <th>-8670749047273764903</th>\n",
              "      <th>-8652741825481604192</th>\n",
              "      <th>...</th>\n",
              "      <th>8791271631167250981</th>\n",
              "      <th>8801420707973230165</th>\n",
              "      <th>8801970869404590779</th>\n",
              "      <th>8813266398846460512</th>\n",
              "      <th>8841741572929644986</th>\n",
              "      <th>8847054836611412804</th>\n",
              "      <th>8855523843512271162</th>\n",
              "      <th>8862260182894039021</th>\n",
              "      <th>8872819156169667456</th>\n",
              "      <th>8874741321583329336</th>\n",
              "      <th>8879844298911979276</th>\n",
              "      <th>8892482595912468268</th>\n",
              "      <th>8907499588729810535</th>\n",
              "      <th>8913362709216003291</th>\n",
              "      <th>8920667914865172372</th>\n",
              "      <th>8940614478925413056</th>\n",
              "      <th>8941502917401491878</th>\n",
              "      <th>8961723342122872302</th>\n",
              "      <th>8965285988346645117</th>\n",
              "      <th>8968131284214320024</th>\n",
              "      <th>8982783231149017560</th>\n",
              "      <th>8992729171160464416</th>\n",
              "      <th>9013651444868609421</th>\n",
              "      <th>9033898219489253274</th>\n",
              "      <th>9037410398700100618</th>\n",
              "      <th>9038446466275805109</th>\n",
              "      <th>9050204922960952289</th>\n",
              "      <th>9090527742744334314</th>\n",
              "      <th>9091970136990402395</th>\n",
              "      <th>9102085903669288476</th>\n",
              "      <th>9105269044962898535</th>\n",
              "      <th>9109075639526981934</th>\n",
              "      <th>9135582630122950040</th>\n",
              "      <th>9137372837662939523</th>\n",
              "      <th>9148269800512008413</th>\n",
              "      <th>9165571805999894845</th>\n",
              "      <th>9187866633451383747</th>\n",
              "      <th>9191849144618614467</th>\n",
              "      <th>9199170757466086545</th>\n",
              "      <th>9210530975708218054</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contentId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <td>0.010399</td>\n",
              "      <td>-0.000193</td>\n",
              "      <td>-0.012547</td>\n",
              "      <td>0.052958</td>\n",
              "      <td>-0.010035</td>\n",
              "      <td>-0.005412</td>\n",
              "      <td>-0.003918</td>\n",
              "      <td>0.049302</td>\n",
              "      <td>-0.013458</td>\n",
              "      <td>-0.020052</td>\n",
              "      <td>-0.009529</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>-0.012044</td>\n",
              "      <td>-0.065134</td>\n",
              "      <td>0.112747</td>\n",
              "      <td>0.041108</td>\n",
              "      <td>-0.010481</td>\n",
              "      <td>-0.005297</td>\n",
              "      <td>-0.034884</td>\n",
              "      <td>-0.123017</td>\n",
              "      <td>-0.008897</td>\n",
              "      <td>-0.042487</td>\n",
              "      <td>0.416457</td>\n",
              "      <td>-0.033627</td>\n",
              "      <td>-0.003643</td>\n",
              "      <td>-0.000428</td>\n",
              "      <td>-0.007387</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.006235</td>\n",
              "      <td>0.058278</td>\n",
              "      <td>-0.028610</td>\n",
              "      <td>0.042954</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.008141</td>\n",
              "      <td>0.134043</td>\n",
              "      <td>-0.003323</td>\n",
              "      <td>0.032243</td>\n",
              "      <td>-0.033136</td>\n",
              "      <td>-0.039186</td>\n",
              "      <td>0.001904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.020430</td>\n",
              "      <td>-0.018576</td>\n",
              "      <td>0.023053</td>\n",
              "      <td>-0.024097</td>\n",
              "      <td>-0.007354</td>\n",
              "      <td>0.013645</td>\n",
              "      <td>-0.018282</td>\n",
              "      <td>-0.014919</td>\n",
              "      <td>-0.009511</td>\n",
              "      <td>-0.019433</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>-0.002602</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>-0.017065</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>-0.001879</td>\n",
              "      <td>-0.002489</td>\n",
              "      <td>0.510757</td>\n",
              "      <td>-0.007451</td>\n",
              "      <td>-0.018229</td>\n",
              "      <td>-0.004900</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.002856</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>-0.007141</td>\n",
              "      <td>-0.006217</td>\n",
              "      <td>0.009393</td>\n",
              "      <td>0.030966</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>-0.089463</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>0.015023</td>\n",
              "      <td>0.020953</td>\n",
              "      <td>-0.009394</td>\n",
              "      <td>-0.019114</td>\n",
              "      <td>-0.029954</td>\n",
              "      <td>-0.018455</td>\n",
              "      <td>-0.015064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <td>0.000819</td>\n",
              "      <td>-0.000313</td>\n",
              "      <td>0.006595</td>\n",
              "      <td>-0.000649</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>-0.000401</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>0.016495</td>\n",
              "      <td>0.009792</td>\n",
              "      <td>0.005556</td>\n",
              "      <td>0.004797</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.008558</td>\n",
              "      <td>0.036923</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>0.019304</td>\n",
              "      <td>-0.009210</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.001836</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.003247</td>\n",
              "      <td>0.009282</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>0.003316</td>\n",
              "      <td>-0.000087</td>\n",
              "      <td>0.007292</td>\n",
              "      <td>0.001487</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.009248</td>\n",
              "      <td>0.006766</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>-0.000612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.001326</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.002428</td>\n",
              "      <td>0.002844</td>\n",
              "      <td>-0.001767</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.004587</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.001862</td>\n",
              "      <td>0.001347</td>\n",
              "      <td>-0.000930</td>\n",
              "      <td>0.016121</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.001562</td>\n",
              "      <td>0.002164</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>0.024945</td>\n",
              "      <td>-0.000414</td>\n",
              "      <td>0.002806</td>\n",
              "      <td>-0.000472</td>\n",
              "      <td>0.002431</td>\n",
              "      <td>-0.000802</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.000775</td>\n",
              "      <td>-0.000109</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>0.014863</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.002391</td>\n",
              "      <td>0.008057</td>\n",
              "      <td>0.004670</td>\n",
              "      <td>0.003277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <td>-0.017253</td>\n",
              "      <td>-0.002646</td>\n",
              "      <td>-0.005907</td>\n",
              "      <td>-0.003666</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>-0.001278</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>-0.014730</td>\n",
              "      <td>-0.023410</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.025522</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>-0.085721</td>\n",
              "      <td>0.058917</td>\n",
              "      <td>0.029974</td>\n",
              "      <td>-0.002729</td>\n",
              "      <td>0.012110</td>\n",
              "      <td>-0.002258</td>\n",
              "      <td>0.015465</td>\n",
              "      <td>-0.002322</td>\n",
              "      <td>0.162668</td>\n",
              "      <td>-0.110257</td>\n",
              "      <td>0.043068</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>0.002378</td>\n",
              "      <td>0.020120</td>\n",
              "      <td>-0.000989</td>\n",
              "      <td>0.095824</td>\n",
              "      <td>0.079587</td>\n",
              "      <td>-0.014877</td>\n",
              "      <td>0.033582</td>\n",
              "      <td>0.004351</td>\n",
              "      <td>0.023526</td>\n",
              "      <td>-0.057510</td>\n",
              "      <td>0.005366</td>\n",
              "      <td>0.082665</td>\n",
              "      <td>0.016139</td>\n",
              "      <td>0.079913</td>\n",
              "      <td>0.022207</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000575</td>\n",
              "      <td>0.013275</td>\n",
              "      <td>-0.005904</td>\n",
              "      <td>-0.010228</td>\n",
              "      <td>0.013855</td>\n",
              "      <td>0.016897</td>\n",
              "      <td>0.077516</td>\n",
              "      <td>-0.003531</td>\n",
              "      <td>0.044262</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>0.057267</td>\n",
              "      <td>0.032941</td>\n",
              "      <td>0.011972</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>0.005471</td>\n",
              "      <td>-0.022793</td>\n",
              "      <td>0.011801</td>\n",
              "      <td>0.001594</td>\n",
              "      <td>-0.002086</td>\n",
              "      <td>0.106361</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.012707</td>\n",
              "      <td>-0.007648</td>\n",
              "      <td>-0.001696</td>\n",
              "      <td>-0.001347</td>\n",
              "      <td>0.020591</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.016003</td>\n",
              "      <td>-0.010067</td>\n",
              "      <td>0.011529</td>\n",
              "      <td>0.046012</td>\n",
              "      <td>0.010485</td>\n",
              "      <td>0.018768</td>\n",
              "      <td>0.150362</td>\n",
              "      <td>0.019052</td>\n",
              "      <td>0.023870</td>\n",
              "      <td>-0.018463</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.133913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <td>0.035081</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>-0.029046</td>\n",
              "      <td>-0.007702</td>\n",
              "      <td>0.017615</td>\n",
              "      <td>0.005496</td>\n",
              "      <td>0.013435</td>\n",
              "      <td>0.057563</td>\n",
              "      <td>0.047532</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.030743</td>\n",
              "      <td>-0.007959</td>\n",
              "      <td>-0.004515</td>\n",
              "      <td>1.021266</td>\n",
              "      <td>0.859355</td>\n",
              "      <td>0.130105</td>\n",
              "      <td>0.013119</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>-0.037711</td>\n",
              "      <td>0.221046</td>\n",
              "      <td>-0.022325</td>\n",
              "      <td>0.222907</td>\n",
              "      <td>0.371801</td>\n",
              "      <td>0.080723</td>\n",
              "      <td>0.015749</td>\n",
              "      <td>-0.004465</td>\n",
              "      <td>0.013157</td>\n",
              "      <td>0.009613</td>\n",
              "      <td>0.148674</td>\n",
              "      <td>0.101845</td>\n",
              "      <td>0.010055</td>\n",
              "      <td>-0.032730</td>\n",
              "      <td>0.015859</td>\n",
              "      <td>-0.024080</td>\n",
              "      <td>0.007765</td>\n",
              "      <td>0.023089</td>\n",
              "      <td>0.089551</td>\n",
              "      <td>-0.032567</td>\n",
              "      <td>0.014871</td>\n",
              "      <td>0.053672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002961</td>\n",
              "      <td>0.022638</td>\n",
              "      <td>0.035891</td>\n",
              "      <td>0.004538</td>\n",
              "      <td>0.038351</td>\n",
              "      <td>0.017527</td>\n",
              "      <td>0.117117</td>\n",
              "      <td>0.030486</td>\n",
              "      <td>0.059079</td>\n",
              "      <td>0.031004</td>\n",
              "      <td>0.127161</td>\n",
              "      <td>-0.010754</td>\n",
              "      <td>0.009569</td>\n",
              "      <td>0.039758</td>\n",
              "      <td>-0.043132</td>\n",
              "      <td>-0.031672</td>\n",
              "      <td>0.018761</td>\n",
              "      <td>-0.001259</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>-0.159150</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.017491</td>\n",
              "      <td>0.015249</td>\n",
              "      <td>-0.005376</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.008552</td>\n",
              "      <td>-0.036104</td>\n",
              "      <td>-0.017412</td>\n",
              "      <td>-0.002377</td>\n",
              "      <td>0.020149</td>\n",
              "      <td>0.260317</td>\n",
              "      <td>0.007923</td>\n",
              "      <td>-0.008079</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>0.013793</td>\n",
              "      <td>-0.010138</td>\n",
              "      <td>0.025703</td>\n",
              "      <td>0.095753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <td>0.019939</td>\n",
              "      <td>-0.004799</td>\n",
              "      <td>0.006684</td>\n",
              "      <td>0.006363</td>\n",
              "      <td>-0.001997</td>\n",
              "      <td>0.002356</td>\n",
              "      <td>0.003876</td>\n",
              "      <td>0.004118</td>\n",
              "      <td>-0.027098</td>\n",
              "      <td>0.019793</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>-0.007241</td>\n",
              "      <td>-0.001459</td>\n",
              "      <td>0.090174</td>\n",
              "      <td>0.056602</td>\n",
              "      <td>0.019968</td>\n",
              "      <td>0.014288</td>\n",
              "      <td>-0.001815</td>\n",
              "      <td>0.009949</td>\n",
              "      <td>0.074134</td>\n",
              "      <td>0.008113</td>\n",
              "      <td>-0.026811</td>\n",
              "      <td>0.086834</td>\n",
              "      <td>0.001820</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>-0.000244</td>\n",
              "      <td>-0.000056</td>\n",
              "      <td>0.001018</td>\n",
              "      <td>-0.005971</td>\n",
              "      <td>-0.004219</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.010301</td>\n",
              "      <td>-0.002499</td>\n",
              "      <td>-0.001984</td>\n",
              "      <td>0.033215</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>0.007714</td>\n",
              "      <td>0.006727</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>-0.018863</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002020</td>\n",
              "      <td>0.002291</td>\n",
              "      <td>-0.007960</td>\n",
              "      <td>0.010172</td>\n",
              "      <td>0.025883</td>\n",
              "      <td>0.005951</td>\n",
              "      <td>0.008581</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>-0.006183</td>\n",
              "      <td>-0.007394</td>\n",
              "      <td>0.006679</td>\n",
              "      <td>0.008037</td>\n",
              "      <td>-0.000914</td>\n",
              "      <td>-0.001107</td>\n",
              "      <td>0.025191</td>\n",
              "      <td>0.020536</td>\n",
              "      <td>-0.001068</td>\n",
              "      <td>0.004137</td>\n",
              "      <td>-0.003468</td>\n",
              "      <td>0.072038</td>\n",
              "      <td>0.001352</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.010380</td>\n",
              "      <td>0.002830</td>\n",
              "      <td>-0.001272</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.001410</td>\n",
              "      <td>-0.001087</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.007533</td>\n",
              "      <td>0.003719</td>\n",
              "      <td>0.004478</td>\n",
              "      <td>0.001917</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>-0.034535</td>\n",
              "      <td>-0.001160</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.002957</td>\n",
              "      <td>0.005991</td>\n",
              "      <td>-0.015662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <td>0.008661</td>\n",
              "      <td>0.006604</td>\n",
              "      <td>0.001463</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>0.008551</td>\n",
              "      <td>-0.001637</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.023148</td>\n",
              "      <td>0.021311</td>\n",
              "      <td>0.007832</td>\n",
              "      <td>0.001862</td>\n",
              "      <td>0.012131</td>\n",
              "      <td>0.662978</td>\n",
              "      <td>0.232488</td>\n",
              "      <td>0.032686</td>\n",
              "      <td>0.010179</td>\n",
              "      <td>0.001035</td>\n",
              "      <td>-0.008432</td>\n",
              "      <td>0.039658</td>\n",
              "      <td>0.003056</td>\n",
              "      <td>0.173182</td>\n",
              "      <td>0.023415</td>\n",
              "      <td>0.047311</td>\n",
              "      <td>0.011608</td>\n",
              "      <td>0.027092</td>\n",
              "      <td>0.032809</td>\n",
              "      <td>0.011769</td>\n",
              "      <td>0.067849</td>\n",
              "      <td>0.068538</td>\n",
              "      <td>0.006881</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>0.008743</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>0.003731</td>\n",
              "      <td>0.007878</td>\n",
              "      <td>0.085175</td>\n",
              "      <td>0.007152</td>\n",
              "      <td>0.032908</td>\n",
              "      <td>0.031513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>0.014946</td>\n",
              "      <td>0.017074</td>\n",
              "      <td>-0.006729</td>\n",
              "      <td>0.026207</td>\n",
              "      <td>0.009541</td>\n",
              "      <td>0.052617</td>\n",
              "      <td>0.015999</td>\n",
              "      <td>0.086161</td>\n",
              "      <td>0.013207</td>\n",
              "      <td>0.059288</td>\n",
              "      <td>0.003799</td>\n",
              "      <td>0.007456</td>\n",
              "      <td>0.011576</td>\n",
              "      <td>0.029934</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.011347</td>\n",
              "      <td>0.002599</td>\n",
              "      <td>0.000936</td>\n",
              "      <td>-0.063401</td>\n",
              "      <td>-0.000762</td>\n",
              "      <td>0.014241</td>\n",
              "      <td>0.042145</td>\n",
              "      <td>0.003431</td>\n",
              "      <td>0.002480</td>\n",
              "      <td>0.009598</td>\n",
              "      <td>0.006749</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.007445</td>\n",
              "      <td>-0.001770</td>\n",
              "      <td>0.024496</td>\n",
              "      <td>0.090091</td>\n",
              "      <td>-0.002703</td>\n",
              "      <td>0.001883</td>\n",
              "      <td>0.098925</td>\n",
              "      <td>0.008484</td>\n",
              "      <td>0.014513</td>\n",
              "      <td>0.016385</td>\n",
              "      <td>0.021794</td>\n",
              "      <td>0.068420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <td>0.046426</td>\n",
              "      <td>0.006374</td>\n",
              "      <td>0.013802</td>\n",
              "      <td>0.010265</td>\n",
              "      <td>-0.002538</td>\n",
              "      <td>-0.004453</td>\n",
              "      <td>0.016615</td>\n",
              "      <td>0.023070</td>\n",
              "      <td>0.059582</td>\n",
              "      <td>0.057307</td>\n",
              "      <td>-0.008076</td>\n",
              "      <td>0.014309</td>\n",
              "      <td>0.009324</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>0.069940</td>\n",
              "      <td>0.022888</td>\n",
              "      <td>0.019393</td>\n",
              "      <td>-0.002733</td>\n",
              "      <td>0.035950</td>\n",
              "      <td>0.226309</td>\n",
              "      <td>0.011492</td>\n",
              "      <td>0.203250</td>\n",
              "      <td>0.139003</td>\n",
              "      <td>0.003948</td>\n",
              "      <td>0.011039</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.024487</td>\n",
              "      <td>0.004025</td>\n",
              "      <td>-0.022678</td>\n",
              "      <td>0.018671</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>0.007163</td>\n",
              "      <td>0.003989</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>0.111115</td>\n",
              "      <td>0.002752</td>\n",
              "      <td>0.027689</td>\n",
              "      <td>0.009010</td>\n",
              "      <td>-0.008062</td>\n",
              "      <td>0.038030</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001439</td>\n",
              "      <td>0.017738</td>\n",
              "      <td>0.017895</td>\n",
              "      <td>0.018256</td>\n",
              "      <td>0.030578</td>\n",
              "      <td>-0.004458</td>\n",
              "      <td>-0.011374</td>\n",
              "      <td>0.011164</td>\n",
              "      <td>0.069509</td>\n",
              "      <td>0.021986</td>\n",
              "      <td>-0.002028</td>\n",
              "      <td>0.013633</td>\n",
              "      <td>0.012919</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.054445</td>\n",
              "      <td>0.023318</td>\n",
              "      <td>0.017506</td>\n",
              "      <td>0.010050</td>\n",
              "      <td>0.013509</td>\n",
              "      <td>-0.009281</td>\n",
              "      <td>-0.003531</td>\n",
              "      <td>-0.006062</td>\n",
              "      <td>0.045090</td>\n",
              "      <td>0.004609</td>\n",
              "      <td>0.005106</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>0.008556</td>\n",
              "      <td>-0.007526</td>\n",
              "      <td>0.008097</td>\n",
              "      <td>0.003667</td>\n",
              "      <td>0.073024</td>\n",
              "      <td>-0.015438</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>-0.005606</td>\n",
              "      <td>-0.000307</td>\n",
              "      <td>0.005250</td>\n",
              "      <td>0.041064</td>\n",
              "      <td>0.030733</td>\n",
              "      <td>0.037113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <td>0.005083</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.002845</td>\n",
              "      <td>-0.001103</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.000754</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>-0.002811</td>\n",
              "      <td>0.003930</td>\n",
              "      <td>0.001525</td>\n",
              "      <td>-0.002338</td>\n",
              "      <td>-0.002054</td>\n",
              "      <td>0.086012</td>\n",
              "      <td>0.043544</td>\n",
              "      <td>0.010337</td>\n",
              "      <td>0.004585</td>\n",
              "      <td>-0.000323</td>\n",
              "      <td>0.006171</td>\n",
              "      <td>0.048949</td>\n",
              "      <td>0.003297</td>\n",
              "      <td>0.007165</td>\n",
              "      <td>0.014215</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>-0.001265</td>\n",
              "      <td>0.000958</td>\n",
              "      <td>0.001162</td>\n",
              "      <td>0.006298</td>\n",
              "      <td>0.002703</td>\n",
              "      <td>0.002775</td>\n",
              "      <td>-0.002741</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>-0.000609</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.004905</td>\n",
              "      <td>-0.000672</td>\n",
              "      <td>-0.007193</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>-0.001064</td>\n",
              "      <td>0.003725</td>\n",
              "      <td>0.009392</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.009278</td>\n",
              "      <td>0.005471</td>\n",
              "      <td>-0.002914</td>\n",
              "      <td>-0.006384</td>\n",
              "      <td>0.006228</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>-0.002035</td>\n",
              "      <td>0.007059</td>\n",
              "      <td>0.003164</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.000652</td>\n",
              "      <td>-0.020237</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.001871</td>\n",
              "      <td>-0.001589</td>\n",
              "      <td>0.001805</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>-0.003708</td>\n",
              "      <td>-0.001839</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.005625</td>\n",
              "      <td>0.019382</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>-0.000992</td>\n",
              "      <td>-0.008110</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.003408</td>\n",
              "      <td>0.003614</td>\n",
              "      <td>0.007607</td>\n",
              "      <td>-0.003650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <td>0.024453</td>\n",
              "      <td>-0.000761</td>\n",
              "      <td>0.000963</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>0.002466</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.009339</td>\n",
              "      <td>-0.003530</td>\n",
              "      <td>-0.007137</td>\n",
              "      <td>0.023221</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>-0.002772</td>\n",
              "      <td>0.005357</td>\n",
              "      <td>0.029106</td>\n",
              "      <td>-0.035731</td>\n",
              "      <td>0.008352</td>\n",
              "      <td>0.009019</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.015860</td>\n",
              "      <td>0.076513</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.003761</td>\n",
              "      <td>-0.003210</td>\n",
              "      <td>0.009588</td>\n",
              "      <td>0.001361</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>0.005732</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>0.008395</td>\n",
              "      <td>-0.002854</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>-0.006640</td>\n",
              "      <td>-0.000491</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.028341</td>\n",
              "      <td>0.002136</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>0.012638</td>\n",
              "      <td>0.010462</td>\n",
              "      <td>-0.015523</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>0.001991</td>\n",
              "      <td>-0.000056</td>\n",
              "      <td>0.003012</td>\n",
              "      <td>0.036182</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.007271</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.003246</td>\n",
              "      <td>0.001211</td>\n",
              "      <td>0.005550</td>\n",
              "      <td>0.015277</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.016810</td>\n",
              "      <td>0.014687</td>\n",
              "      <td>-0.000403</td>\n",
              "      <td>0.003587</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>-0.020227</td>\n",
              "      <td>0.002383</td>\n",
              "      <td>0.006895</td>\n",
              "      <td>-0.001845</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.000726</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.001271</td>\n",
              "      <td>0.004698</td>\n",
              "      <td>-0.001656</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>0.017163</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>-0.016698</td>\n",
              "      <td>0.002045</td>\n",
              "      <td>0.007644</td>\n",
              "      <td>0.000955</td>\n",
              "      <td>0.011074</td>\n",
              "      <td>-0.006657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <td>0.009159</td>\n",
              "      <td>-0.001999</td>\n",
              "      <td>-0.012644</td>\n",
              "      <td>-0.002021</td>\n",
              "      <td>0.005367</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>0.004806</td>\n",
              "      <td>0.013407</td>\n",
              "      <td>-0.003584</td>\n",
              "      <td>0.005989</td>\n",
              "      <td>-0.002432</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>0.181989</td>\n",
              "      <td>0.137465</td>\n",
              "      <td>0.015457</td>\n",
              "      <td>-0.001498</td>\n",
              "      <td>0.001070</td>\n",
              "      <td>-0.014861</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.011550</td>\n",
              "      <td>0.036835</td>\n",
              "      <td>0.026907</td>\n",
              "      <td>0.024941</td>\n",
              "      <td>0.003988</td>\n",
              "      <td>-0.000322</td>\n",
              "      <td>0.004047</td>\n",
              "      <td>0.001844</td>\n",
              "      <td>0.030250</td>\n",
              "      <td>0.021372</td>\n",
              "      <td>0.004068</td>\n",
              "      <td>-0.015686</td>\n",
              "      <td>0.004187</td>\n",
              "      <td>-0.006288</td>\n",
              "      <td>-0.003079</td>\n",
              "      <td>0.007624</td>\n",
              "      <td>0.021903</td>\n",
              "      <td>-0.012791</td>\n",
              "      <td>0.007369</td>\n",
              "      <td>0.006184</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.004319</td>\n",
              "      <td>0.009958</td>\n",
              "      <td>-0.004482</td>\n",
              "      <td>0.007594</td>\n",
              "      <td>0.005363</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.019433</td>\n",
              "      <td>0.008767</td>\n",
              "      <td>0.030724</td>\n",
              "      <td>-0.002472</td>\n",
              "      <td>0.003536</td>\n",
              "      <td>0.008418</td>\n",
              "      <td>-0.017468</td>\n",
              "      <td>-0.009408</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>-0.001562</td>\n",
              "      <td>-0.001737</td>\n",
              "      <td>-0.064916</td>\n",
              "      <td>0.001218</td>\n",
              "      <td>0.005779</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>-0.003272</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>0.001343</td>\n",
              "      <td>-0.004639</td>\n",
              "      <td>-0.004742</td>\n",
              "      <td>-0.000732</td>\n",
              "      <td>0.002485</td>\n",
              "      <td>0.053437</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>-0.003695</td>\n",
              "      <td>0.009582</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>0.003341</td>\n",
              "      <td>-0.007094</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.020589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1140 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      -9223121837663643404  ...   9210530975708218054\n",
              "contentId                                   ...                      \n",
              "-9222795471790223670              0.010399  ...             -0.015064\n",
              "-9216926795620865886              0.000819  ...              0.003277\n",
              "-9194572880052200111             -0.017253  ...              0.133913\n",
              "-9192549002213406534              0.035081  ...              0.095753\n",
              "-9190737901804729417              0.019939  ...             -0.015662\n",
              "-9189659052158407108              0.008661  ...              0.068420\n",
              "-9176143510534135851              0.046426  ...              0.037113\n",
              "-9172673334835262304              0.005083  ...             -0.003650\n",
              "-9171475473795142532              0.024453  ...             -0.006657\n",
              "-9166778629773133902              0.009159  ...              0.020589\n",
              "\n",
              "[10 rows x 1140 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-O-Bzkczuse",
        "colab_type": "code",
        "outputId": "563fcbc1-a260-4af3-e395-fbef8883cd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMXB8sk1zxp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CFRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "    \n",
        "    def __init__(self, cf_predictions_df, items_df=None):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
        "                                    .reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(items_to_ignore)] \\\n",
        "                               .sort_values('recStrength', ascending = False) \\\n",
        "                               .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "cf_recommender_model = CFRecommender(cf_preds_df, articles_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982wmGNkz531",
        "colab_type": "code",
        "outputId": "2798b81e-6880-4efc-c735-578705911f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
        "cf_detailed_results_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Collaborative Filtering (SVD Matrix Factorization) model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Collaborative Filtering', 'recall@5': 0.33405778573254924, 'recall@10': 0.46816670928151366}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_person_id</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>recall@5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>45</td>\n",
              "      <td>21</td>\n",
              "      <td>192</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.109375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-2626634673110551643</td>\n",
              "      <td>56</td>\n",
              "      <td>30</td>\n",
              "      <td>134</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>0.223881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "      <td>130</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.123077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1443636648652872475</td>\n",
              "      <td>51</td>\n",
              "      <td>38</td>\n",
              "      <td>117</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>0.324786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>-2979881261169775358</td>\n",
              "      <td>48</td>\n",
              "      <td>39</td>\n",
              "      <td>88</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.443182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>-3596626804281480007</td>\n",
              "      <td>34</td>\n",
              "      <td>22</td>\n",
              "      <td>80</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1116121227607581999</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>73</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>0.328767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>692689608292948411</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>69</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.231884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-9016528795238256703</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>69</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.289855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3636910968448833585</td>\n",
              "      <td>30</td>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.338235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              _person_id  hits@10_count  ...  recall@10  recall@5\n",
              "76   3609194402293569455             45  ...   0.234375  0.109375\n",
              "17  -2626634673110551643             56  ...   0.417910  0.223881\n",
              "16  -1032019229384696495             34  ...   0.261538  0.123077\n",
              "10  -1443636648652872475             51  ...   0.435897  0.324786\n",
              "82  -2979881261169775358             48  ...   0.545455  0.443182\n",
              "161 -3596626804281480007             34  ...   0.425000  0.275000\n",
              "65   1116121227607581999             32  ...   0.438356  0.328767\n",
              "81    692689608292948411             21  ...   0.304348  0.231884\n",
              "106 -9016528795238256703             28  ...   0.405797  0.289855\n",
              "52   3636910968448833585             30  ...   0.441176  0.338235\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5ZP2Iwiz9jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HybridRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Hybrid'\n",
        "    \n",
        "    def __init__(self, cb_rec_model, cf_rec_model, items_df):\n",
        "        self.cb_rec_model = cb_rec_model\n",
        "        self.cf_rec_model = cf_rec_model\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        #Getting the top-1000 Content-based filtering recommendations\n",
        "        cb_recs_df = self.cb_rec_model.recommend_items(user_id, items_to_ignore=items_to_ignore, verbose=verbose,\n",
        "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCB'})\n",
        "        \n",
        "        #Getting the top-1000 Collaborative filtering recommendations\n",
        "        cf_recs_df = self.cf_rec_model.recommend_items(user_id, items_to_ignore=items_to_ignore, verbose=verbose, \n",
        "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCF'})\n",
        "        \n",
        "        #Combining the results by contentId\n",
        "        recs_df = cb_recs_df.merge(cf_recs_df,\n",
        "                                   how = 'inner', \n",
        "                                   left_on = 'contentId', \n",
        "                                   right_on = 'contentId')\n",
        "        \n",
        "        #Computing a hybrid recommendation score based on CF and CB scores\n",
        "        recs_df['recStrengthHybrid'] = recs_df['recStrengthCB'] * recs_df['recStrengthCF']\n",
        "        \n",
        "        #Sorting recommendations by hybrid score\n",
        "        recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['recStrengthHybrid', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "hybrid_recommender_model = HybridRecommender(content_based_recommender_model, cf_recommender_model, articles_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfN4ZJMb0GW4",
        "colab_type": "code",
        "outputId": "a8e58514-2cf8-48ca-ade9-041c8965ead6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "print('Evaluating Hybrid model...')\n",
        "hybrid_global_metrics, hybrid_detailed_results_df = model_evaluator.evaluate_model(hybrid_recommender_model)\n",
        "print('\\nGlobal metrics:\\n%s' % hybrid_global_metrics)\n",
        "hybrid_detailed_results_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Hybrid model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Hybrid', 'recall@5': 0.4337765277422654, 'recall@10': 0.537969828688315}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_person_id</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>recall@5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>40</td>\n",
              "      <td>27</td>\n",
              "      <td>192</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.140625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-2626634673110551643</td>\n",
              "      <td>56</td>\n",
              "      <td>38</td>\n",
              "      <td>134</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>0.283582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>35</td>\n",
              "      <td>27</td>\n",
              "      <td>130</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>0.207692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1443636648652872475</td>\n",
              "      <td>52</td>\n",
              "      <td>37</td>\n",
              "      <td>117</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.316239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>-2979881261169775358</td>\n",
              "      <td>31</td>\n",
              "      <td>26</td>\n",
              "      <td>88</td>\n",
              "      <td>0.352273</td>\n",
              "      <td>0.295455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>-3596626804281480007</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>80</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1116121227607581999</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>73</td>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.219178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>692689608292948411</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>69</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.202899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-9016528795238256703</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>69</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>0.202899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3636910968448833585</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>68</td>\n",
              "      <td>0.279412</td>\n",
              "      <td>0.235294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              _person_id  hits@10_count  ...  recall@10  recall@5\n",
              "76   3609194402293569455             40  ...   0.208333  0.140625\n",
              "17  -2626634673110551643             56  ...   0.417910  0.283582\n",
              "16  -1032019229384696495             35  ...   0.269231  0.207692\n",
              "10  -1443636648652872475             52  ...   0.444444  0.316239\n",
              "82  -2979881261169775358             31  ...   0.352273  0.295455\n",
              "161 -3596626804281480007             28  ...   0.350000  0.250000\n",
              "65   1116121227607581999             21  ...   0.287671  0.219178\n",
              "81    692689608292948411             23  ...   0.333333  0.202899\n",
              "106 -9016528795238256703             19  ...   0.275362  0.202899\n",
              "52   3636910968448833585             19  ...   0.279412  0.235294\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhoPYEEL0SLE",
        "colab_type": "code",
        "outputId": "6228bd85-d12f-40f5-f808-6c9323047a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "global_metrics_df = pd.DataFrame([pop_global_metrics, cf_global_metrics, cb_global_metrics, hybrid_global_metrics]) \\\n",
        "                        .set_index('modelName')\n",
        "global_metrics_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recall@10</th>\n",
              "      <th>recall@5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modelName</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Popularity</th>\n",
              "      <td>0.372923</td>\n",
              "      <td>0.241754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Collaborative Filtering</th>\n",
              "      <td>0.468167</td>\n",
              "      <td>0.334058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Content-Based</th>\n",
              "      <td>0.524163</td>\n",
              "      <td>0.414600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hybrid</th>\n",
              "      <td>0.537970</td>\n",
              "      <td>0.433777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         recall@10  recall@5\n",
              "modelName                                   \n",
              "Popularity                0.372923  0.241754\n",
              "Collaborative Filtering   0.468167  0.334058\n",
              "Content-Based             0.524163  0.414600\n",
              "Hybrid                    0.537970  0.433777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KTLqq2T0WE4",
        "colab_type": "code",
        "outputId": "e290dc32-e8ca-482a-a3a0-4f75c5de817f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "%matplotlib inline\n",
        "ax = global_metrics_df.transpose().plot(kind='bar', figsize=(15,8))\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\"%.3f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAH+CAYAAAAPn+YOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngSltAAAAA/tfiaVd+D4unpgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7kLVXHZ0Zim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inspect_interactions(person_id, test_set=True):\n",
        "    if test_set:\n",
        "        interactions_df = interactions_test_indexed_df\n",
        "    else:\n",
        "        interactions_df = interactions_train_indexed_df\n",
        "    return interactions_df.loc[person_id].merge(articles_df, how = 'left', \n",
        "                                                      left_on = 'contentId', \n",
        "                                                      right_on = 'contentId') \\\n",
        "                          .sort_values('eventStrength', ascending = False)[['eventStrength', \n",
        "                                                                          'contentId',\n",
        "                                                                          'title', 'url', 'lang']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xe4nzEv-N4f",
        "colab_type": "code",
        "outputId": "1495f625-9c72-4594-fd02-ef0dfad57be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "inspect_interactions(-1479311724257856983, test_set=False).head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>contentId</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>4.285402</td>\n",
              "      <td>7342707578347442862</td>\n",
              "      <td>At eBay, Machine Learning is Driving Innovativ...</td>\n",
              "      <td>https://www.ebayinc.com/stories/news/at-ebay-m...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.129283</td>\n",
              "      <td>621816023396605502</td>\n",
              "      <td>AI Is Here to Help You Write Emails People Wil...</td>\n",
              "      <td>http://www.wired.com/2016/08/boomerang-using-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.044394</td>\n",
              "      <td>-4460374799273064357</td>\n",
              "      <td>Deep Learning for Chatbots, Part 1 - Introduction</td>\n",
              "      <td>http://www.wildml.com/2016/04/deep-learning-fo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>3.954196</td>\n",
              "      <td>-7959318068735027467</td>\n",
              "      <td>Auto-scaling scikit-learn with Spark</td>\n",
              "      <td>https://databricks.com/blog/2016/02/08/auto-sc...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.906891</td>\n",
              "      <td>2589533162305407436</td>\n",
              "      <td>6 reasons why I like KeystoneML</td>\n",
              "      <td>http://radar.oreilly.com/2015/07/6-reasons-why...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.700440</td>\n",
              "      <td>5258604889412591249</td>\n",
              "      <td>Machine Learning Is No Longer Just for Experts</td>\n",
              "      <td>https://hbr.org/2016/10/machine-learning-is-no...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.700440</td>\n",
              "      <td>-398780385766545248</td>\n",
              "      <td>10 Stats About Artificial Intelligence That Wi...</td>\n",
              "      <td>http://www.fool.com/investing/2016/06/19/10-st...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>3.643856</td>\n",
              "      <td>-6467708104873171151</td>\n",
              "      <td>5 reasons your employees aren't sharing their ...</td>\n",
              "      <td>http://justcuriousblog.com/2016/04/5-reasons-y...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3.523562</td>\n",
              "      <td>-4944551138301474550</td>\n",
              "      <td>Algorithms and architecture for job recommenda...</td>\n",
              "      <td>https://www.oreilly.com/ideas/algorithms-and-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3.459432</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>Bad Writing Is Destroying Your Company's Produ...</td>\n",
              "      <td>https://hbr.org/2016/09/bad-writing-is-destroy...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3.459432</td>\n",
              "      <td>444378495316508239</td>\n",
              "      <td>How to choose algorithms for Microsoft Azure M...</td>\n",
              "      <td>https://azure.microsoft.com/en-us/documentatio...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.321928</td>\n",
              "      <td>2468005329717107277</td>\n",
              "      <td>How Netflix does A/B Testing - uxdesign.cc - U...</td>\n",
              "      <td>https://uxdesign.cc/how-netflix-does-a-b-testi...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>3.321928</td>\n",
              "      <td>-8085935119790093311</td>\n",
              "      <td>Graph Capabilities with the Elastic Stack</td>\n",
              "      <td>https://www.elastic.co/webinars/sneak-peek-of-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>-1429167743746492970</td>\n",
              "      <td>Building with Watson Technical Web Series</td>\n",
              "      <td>https://www-304.ibm.com/partnerworld/wps/servl...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>6340108943344143104</td>\n",
              "      <td>Text summarization with TensorFlow</td>\n",
              "      <td>https://research.googleblog.com/2016/08/text-s...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>1525777409079968377</td>\n",
              "      <td>Probabilistic Programming</td>\n",
              "      <td>http://probabilistic-programming.org/wiki/Home</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>-5756697018315640725</td>\n",
              "      <td>Being A Developer After 40 - Free Code Camp</td>\n",
              "      <td>https://medium.freecodecamp.com/being-a-develo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3.087463</td>\n",
              "      <td>2623290164732957912</td>\n",
              "      <td>Creative Applications of Deep Learning with Te...</td>\n",
              "      <td>https://www.kadenze.com/courses/creative-appli...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>279771472506428952</td>\n",
              "      <td>5 Unique Features Of Google Compute Engine Tha...</td>\n",
              "      <td>http://www.forbes.com/sites/janakirammsv/2016/...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>2.906891</td>\n",
              "      <td>-3920124114454832425</td>\n",
              "      <td>Worldwide Ops in Minutes with DataStax &amp; Cloud</td>\n",
              "      <td>http://www.datastax.com/2016/01/datastax-enter...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eventStrength  ...  lang\n",
              "115       4.285402  ...    en\n",
              "38        4.129283  ...    en\n",
              "8         4.044394  ...    en\n",
              "116       3.954196  ...    en\n",
              "10        3.906891  ...    en\n",
              "28        3.700440  ...    en\n",
              "6         3.700440  ...    en\n",
              "113       3.643856  ...    en\n",
              "42        3.523562  ...    en\n",
              "43        3.459432  ...    en\n",
              "41        3.459432  ...    en\n",
              "3         3.321928  ...    en\n",
              "101       3.321928  ...    en\n",
              "107       3.169925  ...    pt\n",
              "16        3.169925  ...    en\n",
              "49        3.169925  ...    en\n",
              "44        3.169925  ...    en\n",
              "97        3.087463  ...    en\n",
              "32        3.000000  ...    en\n",
              "78        2.906891  ...    en\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQy7rnW-R6e",
        "colab_type": "code",
        "outputId": "64652010-7564-4041-cbc6-6b080b79eaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "hybrid_recommender_model.recommend_items(-1479311724257856983, topn=20, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recStrengthHybrid</th>\n",
              "      <th>contentId</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.484696</td>\n",
              "      <td>3269302169678465882</td>\n",
              "      <td>The barbell effect of machine learning.</td>\n",
              "      <td>http://techcrunch.com/2016/06/02/the-barbell-e...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.428711</td>\n",
              "      <td>5092635400707338872</td>\n",
              "      <td>Power to the People: How One Unknown Group of ...</td>\n",
              "      <td>https://medium.com/@atduskgreg/power-to-the-pe...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.411263</td>\n",
              "      <td>5258604889412591249</td>\n",
              "      <td>Machine Learning Is No Longer Just for Experts</td>\n",
              "      <td>https://hbr.org/2016/10/machine-learning-is-no...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.358686</td>\n",
              "      <td>-9033211547111606164</td>\n",
              "      <td>Google's Cloud Machine Learning service is now...</td>\n",
              "      <td>https://techcrunch.com/2016/09/29/googles-clou...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.335053</td>\n",
              "      <td>5250363310227021277</td>\n",
              "      <td>How Google is Remaking Itself as a \"Machine Le...</td>\n",
              "      <td>https://backchannel.com/how-google-is-remaking...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.316371</td>\n",
              "      <td>-7126520323752764957</td>\n",
              "      <td>How Google is Remaking Itself as a \"Machine Le...</td>\n",
              "      <td>https://backchannel.com/how-google-is-remaking...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.316029</td>\n",
              "      <td>7395435905985567130</td>\n",
              "      <td>The AI business landscape</td>\n",
              "      <td>https://www.oreilly.com/ideas/the-ai-business-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.309052</td>\n",
              "      <td>-5756697018315640725</td>\n",
              "      <td>Being A Developer After 40 - Free Code Camp</td>\n",
              "      <td>https://medium.freecodecamp.com/being-a-develo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.295994</td>\n",
              "      <td>-8190931845319543363</td>\n",
              "      <td>Machine Learning Is At The Very Peak Of Its Hy...</td>\n",
              "      <td>https://arc.applause.com/2016/08/17/gartner-hy...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.294210</td>\n",
              "      <td>1415230502586719648</td>\n",
              "      <td>Machine Learning Is Redefining The Enterprise ...</td>\n",
              "      <td>http://www.forbes.com/sites/louiscolumbus/2016...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.285358</td>\n",
              "      <td>621816023396605502</td>\n",
              "      <td>AI Is Here to Help You Write Emails People Wil...</td>\n",
              "      <td>http://www.wired.com/2016/08/boomerang-using-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.282778</td>\n",
              "      <td>201515581783532281</td>\n",
              "      <td>CrowdFlower raises $10 million from Microsoft ...</td>\n",
              "      <td>http://venturebeat.com/2016/06/07/crowdflower-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.276266</td>\n",
              "      <td>-4541461982704074404</td>\n",
              "      <td>Exclusive: Why Microsoft is betting its future...</td>\n",
              "      <td>http://www.theverge.com/2016/7/7/12111028/micr...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.265704</td>\n",
              "      <td>-9128652074338368262</td>\n",
              "      <td>Clarifying the uses of artificial intelligence...</td>\n",
              "      <td>http://techcrunch.com/2016/05/12/clarifying-th...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.260824</td>\n",
              "      <td>8847604225354271039</td>\n",
              "      <td>How to forecast demand with Google BigQuery, p...</td>\n",
              "      <td>https://cloud.google.com/blog/big-data/2016/05...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.257225</td>\n",
              "      <td>-5027816744653977347</td>\n",
              "      <td>Apple acquires Turi, a machine learning company</td>\n",
              "      <td>https://techcrunch.com/2016/08/05/apple-acquir...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.256248</td>\n",
              "      <td>-5253644367331262405</td>\n",
              "      <td>Hello, TensorFlow!</td>\n",
              "      <td>https://www.oreilly.com/learning/hello-tensorflow</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.252939</td>\n",
              "      <td>444378495316508239</td>\n",
              "      <td>How to choose algorithms for Microsoft Azure M...</td>\n",
              "      <td>https://azure.microsoft.com/en-us/documentatio...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.246982</td>\n",
              "      <td>1549650080907932816</td>\n",
              "      <td>Spark comparison: AWS vs. GCP</td>\n",
              "      <td>https://www.oreilly.com/ideas/spark-comparison...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.241448</td>\n",
              "      <td>-6273159470243757969</td>\n",
              "      <td>This startup uses machine learning and satelli...</td>\n",
              "      <td>http://www.theverge.com/2016/8/4/12369494/desc...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    recStrengthHybrid  ...  lang\n",
              "0            0.484696  ...    en\n",
              "1            0.428711  ...    en\n",
              "2            0.411263  ...    en\n",
              "3            0.358686  ...    en\n",
              "4            0.335053  ...    en\n",
              "5            0.316371  ...    en\n",
              "6            0.316029  ...    en\n",
              "7            0.309052  ...    en\n",
              "8            0.295994  ...    en\n",
              "9            0.294210  ...    en\n",
              "10           0.285358  ...    en\n",
              "11           0.282778  ...    en\n",
              "12           0.276266  ...    en\n",
              "13           0.265704  ...    en\n",
              "14           0.260824  ...    en\n",
              "15           0.257225  ...    en\n",
              "16           0.256248  ...    en\n",
              "17           0.252939  ...    en\n",
              "18           0.246982  ...    en\n",
              "19           0.241448  ...    en\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ6dZMuS-kuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}